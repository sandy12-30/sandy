import sys
import os
from optparse import OptionParser
import numpy as np
import time
#image
from PIL import Image
from matplotlib import pyplot as plt
plt.switch_backend('agg')
from pylab import *
import cv2
import random
#import torch.backends.cudnn as cudnn
#pytorch
import torch
import torch.utils.data as Data
import torch.nn as nn
from torch import optim
from torchvision import transforms

from unet import UNet
from preprocess import *

dir_img = './DRIVE/training/images/'#训练图像文件夹
dir_mask = './DRIVE/training/1st_manual/'#图像的结果文件夹
dir_checkpoint = './DRIVE/training/checkpoints/'#训练好的网络保存文件夹！！！！！！！！！！！！！重新写

Nimgs = 20
channels = 3
height = 584
width = 565
patch_height = 48
patch_width = 48
N_subimgs = 4000

# options 是一个字典，其key字典中的关键字可能会是是我们所有的add_option()函数中的dest参数值，
# 其对应的value值，是命令行输入的对应的add_option()函数的参数值。
def get_args():
    parser = OptionParser()
    parser.add_option('-e', '--epochs', dest='epochs', default=250, type='int',#设置迭代数
                      help='number of epochs')
    parser.add_option('-b', '--batch-size', dest='batchsize', default=16,#设置训练批处理数
                      type='int', help='batch size')
    parser.add_option('-l', '--learning-rate', dest='lr', default=0.01,#设置学习率
                      type='float', help='learning rate')
    parser.add_option('-g', '--gpu', action='store_true', dest='gpu',#是否使用GPU，默认是不使用
                      default=True, help='use cuda')
    # parser.add_option('-c', '--load', dest='load',#下载之前预训练好的模型
    #                   default=False, help='load file model')
    (options, args) = parser.parse_args()
    return options
#optParser.parse_args() 剖析并返回一个字典和列表，
#字典中的关键字是我们所有的add_option()函数中的dest参数值，
#而对应的value值，是add_option()函数中的default的参数或者是
#由用户传入optParser.parse_args()的参数
# args,它是一个由 positional arguments 组成的列表


#----------------------------------------------training切片
#check if the patch is fully contained in the FOV
def is_patch_inside_FOV(x,y,img_w,img_h,patch_h):
    x_ = x - int(img_w/2) # origin (0,0) shifted to image center
    y_ = y - int(img_h/2)  # origin (0,0) shifted to image center
    R_inside = 270 - int(patch_h * np.sqrt(2.0) / 2.0) #radius is 270 (from DRIVE db docs), minus the patch diagonal (assumed it is a square #this is the limit to contain the full patch in the FOV
    radius = np.sqrt((x_*x_)+(y_*y_))
    if radius < R_inside:
        return True
    else:
        return False

def extract_random(full_imgs,full_masks, patch_h,patch_w, N_patches, inside=True):
    if (N_patches%full_imgs.shape[0] != 0):
        print("N_patches: plase enter a multiple of 20")
        exit()
    assert (len(full_imgs.shape)==4 and len(full_masks.shape)==4)  #4D arrays
    assert (full_imgs.shape[1]==1 or full_imgs.shape[1]==3)  #check the channel is 1 or 3
    assert (full_masks.shape[1]==1)   #masks only black and white
    assert (full_imgs.shape[2] == full_masks.shape[2] and full_imgs.shape[3] == full_masks.shape[3])
    patches = np.empty((N_patches,full_imgs.shape[1],patch_h,patch_w))
    patches_masks = np.empty((N_patches, full_masks.shape[1], patch_h, patch_w))
    img_h = full_imgs.shape[2]  #height of the full image
    img_w = full_imgs.shape[3] #width of the full image
    # (0,0) in the center of the image
    patch_per_img = int(N_patches/full_imgs.shape[0])  #N_patches equally divided in the full images
    print ("patches per full image: " +str(patch_per_img))
    iter_tot = 0   #iter over the total numbe rof patches (N_patches)
    for i in range(full_imgs.shape[0]):  #loop over the full images
        k=0
        while k <patch_per_img:
            x_center = random.randint(0+int(patch_w/2),img_w-int(patch_w/2))
            y_center = random.randint(0+int(patch_h/2),img_h-int(patch_h/2))

            if inside==True:
                if is_patch_inside_FOV(x_center,y_center,img_w,img_h,patch_h)==False:
                    continue
            patch = full_imgs[i,:,y_center-int(patch_h/2):y_center+int(patch_h/2),x_center-int(patch_w/2):x_center+int(patch_w/2)]
            patch_mask = full_masks[i,:,y_center-int(patch_h/2):y_center+int(patch_h/2),x_center-int(patch_w/2):x_center+int(patch_w/2)]
            patches[iter_tot]=patch
            patches_masks[iter_tot]=patch_mask
            iter_tot +=1   #total
            k+=1  #per full_img

    print("the size of patches and patches_masks:",patches.shape,",",patches_masks.shape)
    return patches, patches_masks

def data_consistency_check(imgs,masks):
    assert(len(imgs.shape)==len(masks.shape))
    assert(imgs.shape[0]==masks.shape[0])
    assert(imgs.shape[2]==masks.shape[2])
    assert(imgs.shape[3]==masks.shape[3])
    assert(masks.shape[1]==1)
    assert(imgs.shape[1]==1 or imgs.shape[1]==3)

def get_patch_training(train_imgs_original,train_masks,patch_height,patch_width,N_subimgs,inside_FOV):

    train_imgs = my_PreProc(train_imgs_original)
    train_masks = train_masks/255.

    train_imgs = train_imgs[:,:,9:574,:]  #cut bottom and top so now it is 565*565
    train_masks = train_masks[:,:,9:574,:]  #cut bottom and top so now it is 565*565。此时图像[张数，通道数，高=宽]
    data_consistency_check(train_imgs,train_masks)

    #check masks are within 0-1
    assert(np.min(train_masks)==0 and np.max(train_masks)==1)

    patches_imgs_train, patches_masks_train = extract_random(train_imgs,train_masks,patch_height,patch_width,N_subimgs,inside_FOV)
    data_consistency_check(patches_imgs_train, patches_masks_train)

    return patches_imgs_train, patches_masks_train#, patches_imgs_test, patches_masks_test

#----------------------------------------------加载自己的数据库
class EyeDataset(Data.Dataset):
    def __init__(self,imags, masks):
        self.imgs = torch.DoubleTensor(imags)
        self.masks = torch.DoubleTensor(masks)

    def __getitem__(self, item):
        imgs, masks = self.imgs[item], self.masks[item]
        return imgs, masks

    def __len__(self):
        return len(self.imgs)

    def __type__(self):
        return self.imgs.dtype

def pred_to_imgs(pred, patch_height, patch_width):
    pred_images = np.zeros((pred.shape[0],pred.shape[1]))

    assert (len(pred.shape)==3)  #3D array: (Npatches,height*width,2)
    assert (pred.shape[2]==2 )  #check the classes are 2
    for a in range(pred.shape[0]):
        for b in range(pred.shape[1]):
            pred_images[a, b] = pred[a, b, 1]

    pred_images = np.reshape(pred_images,(pred_images.shape[0],1, patch_height, patch_width))
    return pred_images
#----------------------------------------------训练调用
def train_net(net,epochs, batch_size, lr, gpu):


    ids_image = get_ids(dir_img)#获取目录
    ids_mask = get_ids(dir_mask)
    print("ID获取成功")
    image = get_image_train(ids_image, dir_img)#得到训练图片（个数，高，宽，通道数）
    mask = get_mask_train(ids_mask, dir_mask)
    print("图片读入成功")
    print("get_image_train:",image.shape)
    print("get_image_mask:",mask.shape)
    # select the patches only inside the FOV  (default == True)得到切分
    patches_imgs_train, patches_masks_train = get_patch_training(image, mask, patch_height,
                                                                 patch_width, N_subimgs,
                                                                 inside_FOV=True  )
    print("预处理并切分成功")
    print("patches_imgs_train:", patches_imgs_train.shape)
    print("patches_masks_train:", patches_masks_train.shape)

    eye_train = EyeDataset(patches_imgs_train, patches_masks_train)
    train_loader = Data.DataLoader(dataset=eye_train,batch_size=batch_size,shuffle=True)
    print('''
    Starting training:
        Epochs: {}
        Batch size: {}
        Learning rate: {}
        Training size: {}
        CUDA: {}
    '''.format(epochs, batch_size, lr, N_subimgs, str(gpu)))

    # 定义优化器
    optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.3,weight_decay=0)
    criterion = nn.CrossEntropyLoss()

    lr_schduler = optim.lr_scheduler.MultiStepLR(optimizer, [0.5*epochs,0.75*epochs], gamma=0.1, last_epoch=-1)

    LOSS = []
    lr_num = []
    best_loss = 1
    print("开始训练")
    for epoch in range(epochs):
        epoch_loss = 1
        net.train()
        a = time.time()
        lr_schduler.step()
        print("Epoch{}/{}".format(epoch, epochs))
        for step,(imgs, true_masks) in enumerate(train_loader):

            if gpu:
                imgs = imgs.float().cuda()
                true_masks = true_masks.float().cuda()
            else:
                imgs = imgs.float()
                true_masks = true_masks.float()

            optimizer.zero_grad()

            pred = net(imgs)  # 图像输入的网络后得到结果masks_pred，结果为灰度图像

            true_masks = true_masks.long()
            true_masks = true_masks.squeeze()

            loss = criterion(pred, true_masks)#对两个结果计算损失
            loss.backward()
            optimizer.step()

            if loss.data < epoch_loss:
                epoch_loss = loss.data
            if epoch_loss <best_loss:
                torch.save(net.state_dict(),'./DRIVE/best_param.pkl')
                best_loss = epoch_loss

        lr_num.append(lr_schduler.get_lr()[0])
        # lr_num.append(lr)

        LOSS.append(epoch_loss)
        print('best loss of this epoch: {0:.6f}'.format(epoch_loss))
        print("cost time of this epoch:", (time.time() - a))
        print("pred(min-max) of this epoch : ", torch.min(pred), ' --- ', torch.max(pred))

    print("best_loss:",best_loss)

    # 保存损失数据

    LOSS = np.array(LOSS)
    x = np.arange(0,epochs,1)
    plt.figure()
    plt.plot(x, LOSS, '-',label='Train loss curve')
    plt.title('Loss')
    plt.xlabel("Epoch")
    plt.ylabel("Train Loss")
    plt.legend(loc="lower left",ncol=2)
    plt.savefig('./DRIVE/result/'+"train_loss.png")

    # 画学习率曲线
    plt.figure()
    lr_num = np.array(lr_num)
    # print("index",index)
    a = np.arange(0,epochs,1)
    plt.plot(a, lr_num, '-', label='Learning Rate Curve ')
    plt.title('Learning Rate')
    plt.xlabel("Epoch")
    plt.ylabel("Learning Rate")
    plt.legend(loc="lower left", ncol=2)
    plt.savefig('./DRIVE/result/' + "Learning Rate.png")

    print("xunlian over ")

if __name__ == '__main__':
    args = get_args()#得到设置的所有参数信息
    #预处理后全部都是一维的
    start_time = time.time()
    net = UNet(n_channels=1, n_classes=2)

    if args.gpu:#是否使用GPU，设置为True，则使用
        net.cuda()
        # cudnn.benchmark = True # faster convolutions, but more memory

    try:#开始训练
        train_net(net=net,
                  epochs=args.epochs,
                  batch_size=args.batchsize,
                  lr=args.lr,
                  gpu=args.gpu)
        print("cost time of this train:", (time.time() - start_time))
    except KeyboardInterrupt:#如果键盘输入ctrl+c停止，则会将结果保存在INTERRUPTED.pth中
        torch.save(net.state_dict(), 'INTERRUPTED.pth')
        print('Saved interrupt')
        try:
            sys.exit(0)
        except SystemExit:
            os._exit(0)
